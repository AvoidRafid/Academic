{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today we focus on basic operations for convolutional layers and on a simple neural network implementation with convolutional layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "# Consider a 2d - window of size 12x12\n",
    "window = np.random.randn(12, 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the sliding window method used in convolutional layers\n",
    "# Dont do the convolution itself, just let the window slide\n",
    "\n",
    "# For that, use a stride of 2\n",
    "# Use a kernel of size 3x3 and slide over the \"window\" variable defined in the previous block\n",
    "# When sliding the kernel over the window with the stride of 2, set always the maximum number of that area to every single entry\n",
    "# E. g. if the window you are currently slicing over looks like this:\n",
    "#  3 4 5\n",
    "#  5 2 6\n",
    "#  1 7 2\n",
    "# then it should be transformed into\n",
    "#  7 7 7\n",
    "#  7 7 7\n",
    "#  7 7 7\n",
    "\n",
    "# Make sure that you update the result always after one complete sliding over the complete window\n",
    "# so that for every calculation you use the original values\n",
    "\n",
    "stride = 2\n",
    "kernel_size = 3\n",
    "\n",
    "def sliding_stride_set_max(window, kernel_size, stride=1):\n",
    "    # Your code here\n",
    "    return None\n",
    "\n",
    "max_slide_window = sliding_stride_set_max(window=window, kernel_size=kernel_size, stride=stride)\n",
    "\n",
    "print(max_slide_window)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement a padding of zeros to the following numpy array\n",
    "to_pad = np.random.randn(6, 6)\n",
    "print(to_pad)\n",
    "\n",
    "# The zero padding should pad the array on every side with size 2\n",
    "# So that they output array of the 6x6 array is of shape 10x10\n",
    "\n",
    "\n",
    "# Your code here\n",
    "padding = None\n",
    "print(padding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement max pooling with the following array (window)\n",
    "to_pool = np.random.randn(6, 6)\n",
    "\n",
    "# Implement the max pooling\n",
    "# Use a stride of 2 and kernel size of 2x2\n",
    "\n",
    "stride = 2\n",
    "kernel_size = 2\n",
    "\n",
    "def max_pooling(window, kernel_size, stride=1):\n",
    "    assert kernel_size >= stride\n",
    "    assert len(window.shape) == 2\n",
    "    assert window.shape[0] % kernel_size == 0\n",
    "    assert window.shape[1] % kernel_size == 0\n",
    "\n",
    "    # Your code here\n",
    "    return None\n",
    "\n",
    "pooling = max_pooling(window=to_pool, kernel_size=kernel_size, stride=stride)\n",
    "print(pooling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First CNN PyTorch implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Implement a small neural network with convolutional layers\n",
    "# 2) Implement a small neural network with linear layers (as in previous practicals)\n",
    "    # make sure that the networks from 1) and 2) have around the same amount of parameters, to make them comparable to each other\n",
    "# 3) Compare the accuracy with the networks from previous practicals, can you improve the accuracy with conv layers?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the FashionMNIST dataset as in previous practicals\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def load_fashion_mnist_data(root_path='./data', batch_size=4):\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5), (0.5))]\n",
    "    )\n",
    "\n",
    "    train_dataset = torchvision.datasets.FashionMNIST(root=root_path, train=True, download=True, transform=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "    test_dataset = torchvision.datasets.FashionMNIST(root=root_path, train=False, download=True, transform=transform)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "    return train_loader, test_loader, train_dataset, test_dataset\n",
    "\n",
    "\n",
    "def plot_fashsion_mnist_images():\n",
    "    _, _, train_dataset, _ = load_fashion_mnist_data()\n",
    "\n",
    "    # get first x items\n",
    "    no = 5\n",
    "    images = [train_dataset.__getitem__(i)[0].permute(1,2,0) for i in range(0, no)]\n",
    "\n",
    "    start_pos = 0\n",
    "    for i in range(no):\n",
    "        plt.subplot(1, no, i+1)\n",
    "        plt.tight_layout()\n",
    "        plt.imshow(images[i], cmap='gray', interpolation='none')\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    plt.show()\n",
    "\n",
    "plot_fashsion_mnist_images()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and evaluation methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the operate method calls the train and eval method\n",
    "# so you only have to call the operate method and pass\n",
    "# the parameters to train and evaluate your model in one line\n",
    "import torch\n",
    "from typing import Callable\n",
    "from torch.optim import Optimizer\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "def train_model(\n",
    "    model: nn.Module, loss_fn: Callable, optimizer: Optimizer,\n",
    "    train_data_loader: DataLoader, epoch: int, batch_size: int = 4, epochs: int = 10, device: torch.device = 'cpu'\n",
    "):\n",
    "    # turn training mode on\n",
    "    model.train()\n",
    "\n",
    "    running_loss = []\n",
    "    running_accuracy = []\n",
    "    for imgs, targets in tqdm.tqdm(train_data_loader, desc=f'Training iteration {epoch + 1}'):\n",
    "        imgs, targets = imgs.to(device=device), targets.to(device=device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(imgs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss.append(loss.item())\n",
    "\n",
    "        # Calculate the Accuracy (how many of all samples are correctly classified?)\n",
    "        max_outputs = torch.max(outputs, dim=1).indices\n",
    "        accuracy = (max_outputs.detach() == targets.detach()).to(dtype=torch.float32).mean()\n",
    "        running_accuracy.append(accuracy)\n",
    "    \n",
    "    return torch.mean(torch.as_tensor(running_loss)), torch.mean(torch.as_tensor(running_accuracy))\n",
    "\n",
    "\n",
    "\n",
    "def eval_model(\n",
    "    model: nn.Module, loss_fn: Callable, val_data_loader: DataLoader, epoch: int, batch_size: int = 4, device: torch.device = 'cpu'\n",
    "):\n",
    "    # turn evaluation mode on\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        running_loss = []\n",
    "        running_accuracy = []\n",
    "        for imgs, targets in tqdm.tqdm(val_data_loader, desc=f'Evaluation iteration {epoch + 1}'):\n",
    "            imgs, targets = imgs.to(device=device), targets.to(device=device)\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(imgs)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "\n",
    "            # print statistics\n",
    "            running_loss.append(loss.item())\n",
    "\n",
    "            # Calculate the Accuracy (how many of all samples are correctly classified?)\n",
    "            max_outputs = torch.max(outputs, dim=1).indices\n",
    "            accuracy = (max_outputs.detach() == targets.detach()).to(dtype=torch.float32).mean()\n",
    "            running_accuracy.append(accuracy)\n",
    "    \n",
    "    return torch.mean(torch.as_tensor(running_loss)), torch.mean(torch.as_tensor(running_accuracy))\n",
    "\n",
    "\n",
    "def operate(model: nn.Module, loss_fn: Callable, optimizer: Optimizer,\n",
    "    train_data_loader: DataLoader, test_data_loader: DataLoader, batch_size: int = 4, epochs: int = 10\n",
    "):\n",
    "    t_losses, t_accs, e_losses, e_accs = [], [], [], []\n",
    "    for epoch in range(epochs):\n",
    "        t_loss, t_acc = train_model(model=model, loss_fn=loss_fn, optimizer=optimizer, train_data_loader=train_data_loader, epoch=epoch, batch_size=batch_size, epochs=epochs)\n",
    "        t_losses.append(t_loss)\n",
    "        t_accs.append(t_acc)\n",
    "\n",
    "        e_loss, e_acc = eval_model(model=model, loss_fn=loss_fn, val_data_loader=test_data_loader, epoch=epoch, batch_size=batch_size)\n",
    "        e_losses.append(e_loss)\n",
    "        e_accs.append(e_accs)\n",
    "\n",
    "        print(f'Training epoch {epoch + 1} finished with loss: {t_loss} and accuracy {t_acc}')\n",
    "        print(f'Eval epoch {epoch + 1} finished with loss: {e_loss} and accuracy {e_acc}')\n",
    "    \n",
    "    return t_losses, t_accs, e_losses, e_accs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method to count the parameters of a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass your model to this function to get the trainable parameters (weights) of your model\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init the datasets\n",
    "batch_size = 4\n",
    "train_data_loader, test_data_loader, _, _ = load_fashion_mnist_data(batch_size=batch_size)\n",
    "\n",
    "# set epochs\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear and Conv model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "### Use the implementation of the linear layer model\n",
    "### and update the layers or extend the layers\n",
    "### to learn the mnist data\n",
    "class LinearLayerModel(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(784, X),\n",
    "            # your layers\n",
    "            nn.Linear(Y, 10)\n",
    "        )\n",
    "    \n",
    "    def forward(self, imgs):\n",
    "        imgs = imgs.reshape(imgs.shape[0], -1)\n",
    "\n",
    "        return self.model(imgs)\n",
    "\n",
    "\n",
    "# Implement your convolutional layer model\n",
    "class ConvLayerModel(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(, ),\n",
    "            nn.Linear(Y, 10)\n",
    "        )\n",
    "    \n",
    "    def forward(self, imgs):\n",
    "        return self.model(imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the convolutional model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F\n",
    "\n",
    "conv_model = ConvLayerModel()\n",
    "print(f'Convolutional model has: {count_parameters(conv_model)} parameters to optimize.')\n",
    "optimizer = \n",
    "\n",
    "loss_fn = \n",
    "\n",
    "conv_t_losses, conv_t_accs, conv_t_iter_losses, conv_t_iter_accs, conv_e_losses, conv_e_accs, conv_e_iter_losses, conv_e_iter_accs = operate(\n",
    "    model=conv_model, loss_fn=loss_fn, optimizer=optimizer,\n",
    "    train_data_loader=train_data_loader, test_data_loader=test_data_loader,\n",
    "    batch_size=batch_size, epochs=epochs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the linear layer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_layer_model = LinearLayerModel()\n",
    "print(f'Linear layer model has: {count_parameters(linear_layer_model)} parameters to optimize.')\n",
    "optimizer = \n",
    "\n",
    "loss_fn = \n",
    "\n",
    "ll_t_losses, ll_t_accs, ll_t_iter_losses, ll_t_iter_accs, ll_e_losses, ll_e_accs, ll_e_iter_losses, ll_e_iter_accs = operate(\n",
    "    model=linear_layer_model, loss_fn=loss_fn, optimizer=optimizer,\n",
    "    train_data_loader=train_data_loader, test_data_loader=test_data_loader,\n",
    "    batch_size=batch_size, epochs=epochs\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the convolutional network with batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_conv_model = ConvLayerModel(...)\n",
    "print(f'Convolutional model with batch normalization has: {count_parameters(bn_conv_model)} parameters to optimize.')\n",
    "optimizer =\n",
    "\n",
    "loss_fn =\n",
    "\n",
    "bn_conv_t_losses, bn_conv_t_accs, bn_conv_t_iter_losses, bn_conv_t_iter_accs, bn_conv_e_losses, bn_conv_e_accs, bn_conv_e_iter_losses, bn_conv_e_iter_accs = operate(\n",
    "    model=bn_conv_model, loss_fn=loss_fn, optimizer=optimizer,\n",
    "    train_data_loader=train_data_loader, test_data_loader=test_data_loader,\n",
    "    batch_size=batch_size, epochs=epochs\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the linear layer network with batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_linear_layer_model = LinearLayerModel(batch_norm=True)\n",
    "print(f'Linear layer model with batch normalization has: {count_parameters(bn_linear_layer_model)} parameters to optimize.')\n",
    "optimizer =\n",
    "\n",
    "loss_fn =\n",
    "\n",
    "bn_ll_t_losses, bn_ll_t_accs, bn_ll_t_iter_losses, bn_ll_t_iter_accs, bn_ll_e_losses, bn_ll_e_accs, bn_ll_e_iter_losses, bn_ll_e_iter_accs = operate(\n",
    "    model=bn_linear_layer_model, loss_fn=loss_fn, optimizer=optimizer,\n",
    "    train_data_loader=train_data_loader, test_data_loader=test_data_loader,\n",
    "    batch_size=batch_size, epochs=epochs\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you did not change the name of return values\n",
    "# from the operate methods of the different models\n",
    "# then you only have to execute the following\n",
    "# cells to visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of elements\n",
    "x_vals = np.arange(0, len(conv_t_iter_losses))\n",
    "x_vals_test_data = [i for i in range(0, len(conv_t_iter_losses), len(x_vals) // len(ll_e_iter_losses))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,6))\n",
    "plt.plot(x_vals, ll_t_iter_losses, label=\"Linear model (Train)\", c=\"red\")\n",
    "plt.plot(x_vals, bn_ll_t_iter_losses, label=\"Linear model with batch norm (Train)\", c=\"blue\")\n",
    "plt.plot(x_vals, conv_t_iter_losses, label=\"Conv model (Train)\", c=\"yellow\")\n",
    "plt.plot(x_vals, bn_conv_t_iter_losses, label=\"Conv model with batch norm (Train)\", c=\"green\")\n",
    "\n",
    "plt.plot(x_vals_test_data, ll_e_iter_losses, label=\"Linear model (Test)\", linestyle = \"dashed\", c= \"red\")\n",
    "plt.plot(x_vals_test_data, bn_ll_e_iter_losses, label=\"Linear model with batch norm (Test)\", linestyle = \"dashed\", c=\"blue\")\n",
    "plt.plot(x_vals_test_data, conv_e_iter_losses, label=\"Conv model (Test)\", linestyle = \"dashed\", c=\"yellow\")\n",
    "plt.plot(x_vals_test_data, bn_conv_e_iter_losses, label=\"Conv model with batch norm (Test)\", linestyle = \"dashed\", c=\"green\")\n",
    "\n",
    "plt.xlabel('Iterationen * 100')\n",
    "plt.ylabel('training loss')\n",
    "plt.title(\"Training no batch norm vs. batch norm\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('aai_2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "25301cabe4c6f833fd20f15b1b22933971919908771eb627a83fe325b4fb6671"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
